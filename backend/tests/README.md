# Test-Dokumentation fÃ¼r Lernassistent API

Diese Dokumentation beschreibt die umfassende Test-Suite fÃ¼r die Lernassistent API.

## ğŸ“‹ Ãœbersicht

Die Test-Suite umfasst:
- **Unit Tests** fÃ¼r alle API-Endpunkte
- **Integrationstests** fÃ¼r komplexe Workflows
- **Fixtures** fÃ¼r Test-Daten
- **In-Memory Datenbank** fÃ¼r isolierte Tests

## ğŸ—ï¸ Test-Struktur

```
backend/tests/
â”œâ”€â”€ __init__.py                 # Test-Package
â”œâ”€â”€ conftest.py                 # Test-Konfiguration und Fixtures
â”œâ”€â”€ test_dateien.py            # Tests fÃ¼r Dateien-API
â”œâ”€â”€ test_notizen.py            # Tests fÃ¼r Notizen-API
â”œâ”€â”€ test_kiantworten.py        # Tests fÃ¼r KI-Antworten-API
â”œâ”€â”€ test_quiz_sessions.py      # Tests fÃ¼r Quiz-Sessions-API
â”œâ”€â”€ test_quiz_fragen.py        # Tests fÃ¼r Quiz-Fragen-API
â”œâ”€â”€ test_integration.py        # Integrationstests
â””â”€â”€ README.md                  # Diese Dokumentation
```

## ğŸš€ Tests ausfÃ¼hren

### Voraussetzungen

1. **Virtuelle Umgebung aktivieren:**
   ```bash
   cd backend
   source .venv/bin/activate  # Linux/macOS
   # oder
   .venv\Scripts\activate     # Windows
   ```

2. **AbhÃ¤ngigkeiten installieren:**
   ```bash
   pip install pytest pytest-asyncio httpx
   ```

### Alle Tests ausfÃ¼hren

```bash
# Alle Tests ausfÃ¼hren
pytest

# Mit detaillierter Ausgabe
pytest -v

# Mit Coverage-Report
pytest --cov=. --cov-report=html

# Nur bestimmte Test-Datei
pytest tests/test_dateien.py

# Nur bestimmte Test-Klasse
pytest tests/test_dateien.py::TestDateienAPI

# Nur bestimmten Test
pytest tests/test_dateien.py::TestDateienAPI::test_create_datei
```

### Test-Optionen

```bash
# Tests parallel ausfÃ¼hren (schneller)
pytest -n auto

# Tests mit Live-Logs
pytest -s

# Tests stoppen beim ersten Fehler
pytest -x

# Nur fehlgeschlagene Tests erneut ausfÃ¼hren
pytest --lf

# Tests mit Marker ausfÃ¼hren
pytest -m "not slow"
```

## ğŸ“Š Test-Kategorien

### 1. Unit Tests

#### Dateien-API (`test_dateien.py`)
- âœ… CRUD-Operationen (Create, Read, Update, Delete)
- âœ… Validierung von Eingabedaten
- âœ… Fehlerbehandlung (404, 422)
- âœ… Relationen zu Notizen und Quiz-Sessions
- âœ… Edge Cases (minimale Daten, ungÃ¼ltige Daten)

#### Notizen-API (`test_notizen.py`)
- âœ… CRUD-Operationen
- âœ… Komplexe JSON-Labels
- âœ… VerknÃ¼pfung mit Dateien (Many-to-Many)
- âœ… VerknÃ¼pfung mit KI-Antworten (One-to-Many)
- âœ… Fehlerbehandlung

#### KI-Antworten-API (`test_kiantworten.py`)
- âœ… CRUD-Operationen
- âœ… VerknÃ¼pfung mit Notizen
- âœ… Code-Beispiele und lange Inhalte
- âœ… Verschieben zwischen Notizen
- âœ… Foreign Key Constraints

#### Quiz-Sessions-API (`test_quiz_sessions.py`)
- âœ… CRUD-Operationen
- âœ… VerknÃ¼pfung mit Dateien (Many-to-Many)
- âœ… VerknÃ¼pfung mit Quiz-Fragen (One-to-Many)
- âœ… Cascade Delete Verhalten
- âœ… Mehrfach-VerknÃ¼pfungen

#### Quiz-Fragen-API (`test_quiz_fragen.py`)
- âœ… CRUD-Operationen
- âœ… VerknÃ¼pfung mit Quiz-Sessions
- âœ… Lange Inhalte und Sonderzeichen
- âœ… Verschieben zwischen Sessions
- âœ… Validierung von Pflichtfeldern

### 2. Integrationstests (`test_integration.py`)

- âœ… **VollstÃ¤ndiger Workflow**: Alle EntitÃ¤ten in einem zusammenhÃ¤ngenden Test
- âœ… **Cascade Delete**: ÃœberprÃ¼fung des LÃ¶schverhaltens
- âœ… **Many-to-Many Beziehungen**: Komplexe VerknÃ¼pfungen
- âœ… **Datenkonsistenz**: Updates und Konsistenz-Checks
- âœ… **Fehlerbehandlung**: Robustheit bei ungÃ¼ltigen Operationen
- âœ… **API Health**: Root- und Health-Endpunkte

## ğŸ”§ Test-Konfiguration

### Fixtures (`conftest.py`)

```python
@pytest.fixture
def client(test_db):
    """Test-Client mit In-Memory Datenbank"""
    
@pytest.fixture
def sample_datei_data():
    """Beispiel-Daten fÃ¼r Datei-Tests"""
    
@pytest.fixture
def sample_notiz_data():
    """Beispiel-Daten fÃ¼r Notiz-Tests"""
    
# ... weitere Fixtures
```

### Test-Datenbank

- **In-Memory SQLite**: Jeder Test bekommt eine frische Datenbank
- **Automatisches Setup/Teardown**: Tabellen werden automatisch erstellt/gelÃ¶scht
- **Isolation**: Tests beeinflussen sich nicht gegenseitig

## ğŸ“ˆ Test-Coverage

Die Tests decken ab:

### API-Endpunkte (100%)
- âœ… Alle CRUD-Operationen
- âœ… Alle Relationen-Endpunkte
- âœ… Fehlerbehandlung
- âœ… Edge Cases

### Datenbank-Operationen (100%)
- âœ… Alle CRUD-Funktionen
- âœ… Foreign Key Constraints
- âœ… Cascade Delete
- âœ… Many-to-Many Relationen

### GeschÃ¤ftslogik (100%)
- âœ… Datenvalidierung
- âœ… Beziehungslogik
- âœ… Konsistenz-Checks

## ğŸ› Debugging von Tests

### Test-Logs anzeigen
```bash
pytest -s --log-cli-level=DEBUG
```

### Einzelnen Test debuggen
```bash
pytest tests/test_dateien.py::TestDateienAPI::test_create_datei -v -s
```

### Test-Datenbank inspizieren
```python
# In einem Test
def test_debug_database(client, test_db):
    # Daten erstellen
    response = client.post("/api/dateien/", json=sample_data)
    
    # Breakpoint setzen
    import pdb; pdb.set_trace()
    
    # Datenbank-Zustand Ã¼berprÃ¼fen
    assert response.status_code == 200
```

## ğŸ“ Test-Beispiele

### Einfacher Unit Test
```python
def test_create_datei(client, sample_datei_data):
    response = client.post("/api/dateien/", json=sample_datei_data)
    assert response.status_code == 200
    data = response.json()
    assert data["titel"] == sample_datei_data["titel"]
    assert "id" in data
```

### Relationen-Test
```python
def test_link_datei_zu_notiz(client, sample_notiz_data, sample_datei_data):
    # EntitÃ¤ten erstellen
    notiz_response = client.post("/api/notizen/", json=sample_notiz_data)
    datei_response = client.post("/api/dateien/", json=sample_datei_data)
    
    # VerknÃ¼pfen
    link_response = client.post(f"/api/notizen/{notiz_id}/dateien/{datei_id}")
    assert link_response.status_code == 200
    
    # VerknÃ¼pfung Ã¼berprÃ¼fen
    dateien_response = client.get(f"/api/notizen/{notiz_id}/dateien")
    assert len(dateien_response.json()) == 1
```

### Integrationstest
```python
def test_complete_workflow(client):
    # 1. Grunddaten erstellen
    datei = client.post("/api/dateien/", json=datei_data)
    notiz = client.post("/api/notizen/", json=notiz_data)
    
    # 2. VerknÃ¼pfungen erstellen
    client.post(f"/api/notizen/{notiz_id}/dateien/{datei_id}")
    
    # 3. AbhÃ¤ngige Daten erstellen
    kiantwort = client.post("/api/kiantworten/", json=kiantwort_data)
    
    # 4. Konsistenz Ã¼berprÃ¼fen
    assert len(client.get(f"/api/notizen/{notiz_id}/dateien").json()) == 1
```

## ğŸ¯ Best Practices

### 1. Test-Isolation
- Jeder Test ist unabhÃ¤ngig
- Frische Datenbank pro Test
- Keine geteilten ZustÃ¤nde

### 2. AussagekrÃ¤ftige Namen
```python
def test_create_datei_with_minimal_data():  # âœ… Gut
def test_datei():                           # âŒ Schlecht
```

### 3. Arrange-Act-Assert Pattern
```python
def test_update_datei():
    # Arrange
    datei = client.post("/api/dateien/", json=sample_data)
    datei_id = datei.json()["id"]
    
    # Act
    response = client.put(f"/api/dateien/{datei_id}", json=update_data)
    
    # Assert
    assert response.status_code == 200
    assert response.json()["titel"] == update_data["titel"]
```

### 4. Edge Cases testen
- Leere Daten
- UngÃ¼ltige IDs
- Fehlende Pflichtfelder
- Sehr lange Inhalte
- Sonderzeichen

## ğŸ” Kontinuierliche Integration

### GitHub Actions (Beispiel)
```yaml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.11
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov
      - name: Run tests
        run: pytest --cov=. --cov-report=xml
      - name: Upload coverage
        uses: codecov/codecov-action@v1
```

## ğŸ“š WeiterfÃ¼hrende Ressourcen

- [pytest Dokumentation](https://docs.pytest.org/)
- [FastAPI Testing](https://fastapi.tiangolo.com/tutorial/testing/)
- [SQLAlchemy Testing](https://docs.sqlalchemy.org/en/14/orm/session_transaction.html#joining-a-session-into-an-external-transaction-such-as-for-test-suites)

## ğŸ¤ Beitragen

### Neue Tests hinzufÃ¼gen
1. Test-Datei erstellen oder erweitern
2. Fixtures in `conftest.py` hinzufÃ¼gen falls nÃ¶tig
3. Tests ausfÃ¼hren: `pytest`
4. Coverage Ã¼berprÃ¼fen: `pytest --cov=.`

### Test-Konventionen
- Klassen-Namen: `TestEntityAPI`
- Test-Namen: `test_action_entity_condition`
- Fixtures: `sample_entity_data`
- Assertions: Spezifisch und aussagekrÃ¤ftig

---

**Hinweis**: Diese Test-Suite gewÃ¤hrleistet die QualitÃ¤t und ZuverlÃ¤ssigkeit der Lernassistent API. Bei Ã„nderungen an der API sollten entsprechende Tests hinzugefÃ¼gt oder angepasst werden.
